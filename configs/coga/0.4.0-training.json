{
    "datasets": [
        {
            "data_class": "DineshChitChatDataset",
            "data_name": "chitchat",
            "data_path": "../data/chitchat/chitchat_v2/",
            "data_sampling_proportion": 3,
            "max_input_tokens": 1024,
            "max_output_tokens": 256,
            "dataset_type": "response_evidence",
            "combine_no_evidence": true,
            "files": {
                "train": "chitchat_subdocs_train.json",
                "val": "chitchat_subdocs_val.json",
                "test": "chitchat_document_test.json"
            }
        },
        {
            "data_class": "YatinAnswerabilityDataset",
            "data_name": "multidoc2dial",
            "data_path": "../data/md2d/contextual_unanswerable_classifier/",
            "data_sampling_proportion": 7,
            "max_input_tokens": 1024,
            "max_output_tokens": 256,
            "dataset_type": "response_evidence",
            "combine_no_evidence": true,
            "files": {
                "train": "md2d_subdocs_train_pos_neg.json",
                "val": "md2d_subdocs_val_pos_neg.json",
                "test": "md2d_document_test_pos_neg.json"
            }
        }
    ],
    "model_name": "mosaicml/mpt-7b",
    "model_class": "AutoModelForCausalLM",
    "trust_remote_code": true,
    "training_inference_type": "full_finetuning",
    "logdir": "/cos/mayank/aim-repo",
    "experiment_name": "coga-7b-0.4.0",
    "save_path": "/cos/mayank/checkpoints/coga-7b-0.4.0",
    "num_training_steps": 20000,
    "eval_interval": 1000,
    "save_interval": 4000,
    "batch_size_per_gpu": 2,
    "dtype": "bfloat16",
    "optimizer": {
        "optimizer_class": "ApexFusedAdam",
        "lr": 1e-5,
        "weight_decay": 0.1,
        "betas": [0.9, 0.95],
        "eps": 1e-10
    },
    "lr_schedule": "cosine"
}
