{
    "datasets": [
        {
            "data_class": "YatinAnswerabilityDataset",
            "data_name": "eli5",
            "data_path": "../multidoc2dial-data-forge/qa/v3/eli5_processed",
            "data_sampling_proportion": 350,
            "max_input_tokens": 1024,
            "max_output_tokens": 256,
            "filter_functions": ["is_bertscore_high"],
            "bertscore_threshold": 0.1,
            "dataset_type": "no_evidence",
            "combine_no_evidence": true,
            "filter_allowed": false,
            "files": {
                "train": "pos_best_train_orig.json_ans_retrieved.json",
                "val": "pos_best_dev_orig.json_ans_retrieved.json",
                "test": "pos_best_dev_orig.json_ans_retrieved.json"
            }
        },
        {
            "data_class": "YatinAnswerabilityDataset",
            "data_name": "multidoc2dial",
            "data_path": "../multidoc2dial-data-forge/augmented_multidoc2dial/v3/contextual_unanswerable_classifier_with_da/",
            "data_sampling_proportion": 500,
            "max_input_tokens": 1024,
            "max_output_tokens": 256,
            "filter_functions": ["is_da_type_allowed"],
            "allowed_da_types": ["idk", "respond_solution", "respond_solution_positive", "respond_solution_negative"],
            "dataset_type": "no_evidence",
            "combine_no_evidence": true,
            "filter_allowed": true,
            "files": {
                "train": "md2d_subdocs_train_pos_neg.json",
                "val": "md2d_subdocs_val_pos_neg.json",
                "test": "md2d_document_test_pos_neg.json"
            }
        }

    ],
    "model_name": "google/flan-t5-xl",
    "additional_special_tokens": ["\n"],
    "model_class": "AutoModelForSeq2SeqLM",
    "training_inference_type": "full_finetuning",
    "logdir": "/cos/mayank/aim-repo",
    "experiment_name": "coga-3b-0.5.1",
    "save_path": "/cos/mayank/checkpoints/coga-3b-0.5.1",
    "num_training_steps": 20000,
    "eval_interval": 2000,
    "save_interval": 4000,
    "batch_size_per_gpu": 2,
    "dtype": "bfloat16",
    "optimizer": {
        "optimizer_class": "ApexFusedAdam",
        "lr": 1e-5,
        "weight_decay": 0.1,
        "betas": [0.9, 0.95],
        "eps": 1e-10
    },
    "lr_schedule": "cosine"
}
