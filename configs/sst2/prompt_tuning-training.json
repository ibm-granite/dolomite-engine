{
    "datasets": [
        {
            "class_name": "SST2Dataset",
            "data_name": "sst2",
            "input_format": "\n__input__\nSentiment:",
            "output_format": " __output__",
            "data_sampling_ratio": 1,
            "max_input_tokens": 1024,
            "max_output_tokens": 128
        }
    ],
    "model_args": {
        "model_name": "bigscience/bloom-560m",
        "model_class": "AutoModelForCausalLM",
        "dtype": "bfloat16"
    },
    "tuning_args": {
        "tuning_method": "prompt_tuning",
        "prompt_tuning_args": {
            "prompt_tuning_init": "TEXT",
            "prompt_tuning_init_text": "Classify the sentiment of the sentence:",
            "num_virtual_tokens": 8
        }
    },
    "logging_args": {
        "experiment_name": "sst2-bloom-560m-prompt_tuning"
    },
    "save_args": {
        "save_path": "checkpoints/prompt_tuning",
        "save_interval": 500
    },
    "training_parameters": {
        "num_training_steps": 4000,
        "eval_interval": 500,
        "batch_size_per_gpu": 8
    },
    "optimizer_args": {
        "class_name": "ApexFusedAdam",
        "class_args": 
        {
            "lr": 1e-5,
            "weight_decay": 0.1,
            "betas": [0.9, 0.95],
            "eps": 1e-10
        }
    },
    "lr_scheduler_args": {
        "lr_schedule": "cosine"
    }
}
